import { NextRequest, NextResponse } from 'next/server';
import { promises as fs } from 'fs';
import path from 'path';
import os from 'os';
import { spawn } from 'child_process';

interface Scene {
  title: string;
  description: string;
  duration: number;
  transition: string;
  backgroundVideo?: string;
  backgroundImage?: string;
  textPosition: string;
}

interface FrameData {
  width: number;
  height: number;
  data: Uint8Array;
}

// Lazy-load FFmpeg to avoid build-time issues
async function getFFmpeg() {
  try {
    const ffmpeg = (await import('fluent-ffmpeg')).default;
    const ffmpegInstaller = (await import('@ffmpeg-installer/ffmpeg')).default;
    
    // Set FFmpeg path
    ffmpeg.setFfmpegPath(ffmpegInstaller.path);
    
    return ffmpeg;
  } catch (error) {
    console.error('‚ö†Ô∏è FFmpeg not available:', error);
    throw new Error('FFmpeg is not available in this environment');
  }
}

export async function POST(request: NextRequest) {
  let script: string = '';
  let voiceUrl: string | undefined;
  let musicUrl: string | undefined;
  let scenes: Scene[] = [];
  let videoType: string = '';
  let duration: number = 0;
  let width: number = 1920;
  let height: number = 1080;
  
  try {
    const requestData = await request.json();
    script = requestData.script;
    voiceUrl = requestData.voiceUrl;
    musicUrl = requestData.musicUrl;
    scenes = requestData.scenes;
    videoType = requestData.videoType;
    duration = requestData.duration;    if (!script || !scenes || !videoType || !duration) {
      return NextResponse.json(
        { error: 'Missing required parameters for video rendering' },
        { status: 400 }
      );
    }

    console.log('üé¨ Starting REAL video generation with FFmpeg...');
    
    // Get video dimensions
    const dimensions = getVideoDimensions(videoType);
    width = dimensions.width;
    height = dimensions.height;
    
    // Generate real video content using browser canvas + FFmpeg
    const videoData = await generateRealVideoWithFFmpeg({
      script,
      scenes,
      videoType,
      duration,
      width,
      height,
      voiceUrl,
      musicUrl
    });

    console.log('‚úÖ Real video generation complete!');

    return NextResponse.json({
      videoUrl: videoData.videoUrl,
      isBase64: true,
      urlLength: videoData.videoUrl.length,
      metadata: {
        videoType,
        duration,
        sceneCount: scenes.length,
        aspectRatio: getAspectRatio(videoType),
        resolution: `${width}x${height}`,
        voiceProvider: voiceUrl ? 'Custom' : 'None',
        musicProvider: musicUrl ? 'Custom' : 'None',
        renderingSteps: videoData.renderingSteps,
        renderedAt: new Date().toISOString(),
        fileSize: videoData.fileSize,
        format: 'MP4',
        encoding: 'base64',
        isRealVideo: true
      }
    });
  } catch (error) {
    console.error('Video rendering error:', error);
    
    // If FFmpeg is not available, provide a fallback response
    if (error instanceof Error && error.message.includes('FFmpeg')) {
      console.log('üîÑ FFmpeg not available - providing fallback response');
      
      return NextResponse.json({
        videoUrl: 'data:video/mp4;base64,AAAAIGZ0eXBpc29tAAACAGlzb21pc284bXA0MQAAAghta2RhdGEAAAKoAAACoA==',
        isBase64: true,
        urlLength: 94,
        error: 'FFmpeg not available in build environment - using fallback',
        metadata: {
          videoType,
          duration,
          sceneCount: scenes.length,
          aspectRatio: getAspectRatio(videoType),
          resolution: `${width}x${height}`,
          voiceProvider: voiceUrl ? 'Custom' : 'None',
          musicProvider: musicUrl ? 'Custom' : 'None',
          renderingSteps: ['Error: FFmpeg unavailable'],
          renderedAt: new Date().toISOString(),
          fileSize: 'Unknown',
          format: 'MP4',
          encoding: 'base64',
          isRealVideo: false,
          fallbackReason: 'FFmpeg not available in deployment environment'
        }
      });
    }
    
    return NextResponse.json(
      { error: 'Failed to render video: ' + (error as Error).message },
      { status: 500 }
    );
  }
}

// Generate real video using browser Canvas API + FFmpeg
async function generateRealVideoWithFFmpeg(options: {
  script: string;
  scenes: Scene[];
  videoType: string;
  duration: number;
  width: number;
  height: number;
  voiceUrl?: string;
  musicUrl?: string;
}) {
  const { scenes, width, height, duration, voiceUrl, musicUrl } = options;
  
  const renderingSteps = [
    'Initializing real video generator...',
    'Creating canvas frames with browser API...',
    'Processing scenes with text overlays...',
    'Generating keyframes at 30fps...',
    'Setting up FFmpeg encoding...',
    'Encoding video with audio...',
    'Converting to Base64 MP4...'
  ];

  console.log('üìΩÔ∏è Creating real video frames with Canvas API...');
  
  // Create temporary directory for frames
  const tempDir = path.join(os.tmpdir(), `video_${Date.now()}`);
  await fs.mkdir(tempDir, { recursive: true });
  
  try {
    // Generate frames using browser-style canvas
    const frameRate = 30;
    const totalFrames = Math.floor(duration * frameRate);
    const framePaths: string[] = [];
    
    for (let frameIndex = 0; frameIndex < totalFrames; frameIndex++) {
      const timeInVideo = frameIndex / frameRate;
      const currentScene = getCurrentScene(scenes, timeInVideo, duration);
      
      if (currentScene) {
        const frameData = await generateCanvasFrame({
          scene: currentScene,
          width,
          height,
          timeInScene: timeInVideo,
          frameIndex,
          totalFrames
        });
        
        // Save frame as PNG
        const framePath = path.join(tempDir, `frame_${frameIndex.toString().padStart(6, '0')}.png`);
        await saveFrameAsPNG(frameData, framePath);
        framePaths.push(framePath);
      }
      
      // Log progress every 30 frames
      if (frameIndex % 30 === 0) {
        console.log(`üéûÔ∏è Generated frame ${frameIndex + 1}/${totalFrames}`);
      }
    }

    console.log(`‚úÖ Generated ${framePaths.length} frames`);
    
    // Encode video with FFmpeg
    const outputPath = path.join(tempDir, 'output.mp4');
    await encodeVideoWithFFmpeg({
      framePaths,
      outputPath,
      width,
      height,
      frameRate,
      duration,
      voiceUrl,
      musicUrl,
      tempDir
    });
    
    // Convert to base64
    const videoBuffer = await fs.readFile(outputPath);
    const base64Video = videoBuffer.toString('base64');
    const videoUrl = `data:video/mp4;base64,${base64Video}`;
    
    // Cleanup
    await cleanupTempFiles(tempDir);
    
    return {
      videoUrl,
      renderingSteps,
      fileSize: `${(videoBuffer.length / (1024 * 1024)).toFixed(2)} MB`
    };
    
  } catch (error) {    // Cleanup on error
    await cleanupTempFiles(tempDir);
    throw error;
  }
}

// Generate a frame using browser-style Canvas API operations
async function generateCanvasFrame(options: {
  scene: Scene;
  width: number;
  height: number;
  timeInScene: number;
  frameIndex: number;
  totalFrames: number;
}): Promise<FrameData> {
  const { scene, width, height, timeInScene, frameIndex, totalFrames } = options;
  
  // Create ImageData-like structure (similar to browser Canvas)
  const imageData = new Uint8Array(width * height * 4); // RGBA
  
  // Create background gradient
  const bgColors = getSceneBackgroundGradient(scene, timeInScene);
  fillCanvasWithGradient(imageData, width, height, bgColors);
  
  // Add animated elements
  addAnimatedBackground(imageData, width, height, frameIndex, totalFrames);
  
  // Add text overlay with animation
  if (scene.title || scene.description) {
    addAnimatedTextOverlay(imageData, width, height, {
      title: scene.title,
      description: scene.description,
      position: scene.textPosition,
      frameIndex,
      totalFrames
    });
  }
  
  // Add transition effects
  if (scene.transition && scene.transition !== 'none') {
    applyTransitionEffect(imageData, width, height, scene.transition, frameIndex, totalFrames);
  }
  
  return {
    width,
    height,
    data: imageData
  };
}

function getSceneBackgroundGradient(scene: Scene, timeInScene: number): Array<{r: number, g: number, b: number}> {
  // Create beautiful gradients based on scene content
  const gradients = [
    [{ r: 17, g: 24, b: 39 }, { r: 88, g: 28, b: 135 }],   // Dark blue to purple
    [{ r: 91, g: 33, b: 182 }, { r: 236, g: 72, b: 153 }], // Purple to pink
    [{ r: 6, g: 182, b: 212 }, { r: 34, g: 197, b: 94 }],  // Cyan to green
    [{ r: 251, g: 113, b: 133 }, { r: 251, g: 191, b: 36 }], // Pink to yellow
    [{ r: 59, g: 130, b: 246 }, { r: 147, g: 51, b: 234 }], // Blue to purple
  ];
  
  const gradientIndex = Math.abs(scene.title.charCodeAt(0)) % gradients.length;
  return gradients[gradientIndex];
}

function fillCanvasWithGradient(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  colors: Array<{r: number, g: number, b: number}>
) {
  for (let y = 0; y < height; y++) {
    for (let x = 0; x < width; x++) {
      const progress = y / height;
      const color1 = colors[0];
      const color2 = colors[1];
      
      // Linear interpolation between colors
      const r = Math.round(color1.r + (color2.r - color1.r) * progress);
      const g = Math.round(color1.g + (color2.g - color1.g) * progress);
      const b = Math.round(color1.b + (color2.b - color1.b) * progress);
      
      const index = (y * width + x) * 4;
      imageData[index] = r;     // Red
      imageData[index + 1] = g; // Green
      imageData[index + 2] = b; // Blue
      imageData[index + 3] = 255; // Alpha
    }
  }
}

function addAnimatedBackground(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  frameIndex: number, 
  totalFrames: number
) {
  // Add animated particles/shapes
  const time = frameIndex / totalFrames;
  const numParticles = 15;
  
  for (let i = 0; i < numParticles; i++) {
    const particleTime = (time + i / numParticles) % 1;
    const x = Math.floor((Math.sin(particleTime * Math.PI * 2 + i) * 0.3 + 0.5) * width);
    const y = Math.floor((particleTime) * height);
    const size = 3 + Math.sin(frameIndex * 0.1 + i) * 2;
    
    drawCircle(imageData, width, height, x, y, size, { r: 255, g: 255, b: 255, a: 100 });
  }
}

function addAnimatedTextOverlay(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  text: {
    title: string;
    description: string;
    position: string;
    frameIndex: number;
    totalFrames: number;
  }
) {
  const { title, description, frameIndex, totalFrames, position } = text;
  
  // Calculate text position
  let textY = Math.floor(height * 0.5);
  if (position === 'top') textY = Math.floor(height * 0.2);
  if (position === 'bottom') textY = Math.floor(height * 0.8);
  
  // Animate text appearance
  const fadeProgress = Math.min(1, frameIndex / (totalFrames * 0.1));
  const slideOffset = (1 - fadeProgress) * 50;
  
  if (title) {
    drawText(imageData, width, height, title, {
      x: Math.floor(width * 0.1) + slideOffset,
      y: textY - 40,
      size: 'large',
      color: { r: 255, g: 255, b: 255, a: Math.floor(255 * fadeProgress) }
    });
  }
  
  if (description) {
    drawText(imageData, width, height, description, {
      x: Math.floor(width * 0.1) + slideOffset,
      y: textY + 20,
      size: 'medium',
      color: { r: 200, g: 200, b: 200, a: Math.floor(200 * fadeProgress) }
    });
  }
}

function applyTransitionEffect(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  transition: string, 
  frameIndex: number, 
  totalFrames: number
) {
  // Apply transition effects like fade, slide, etc.
  const progress = frameIndex / totalFrames;
  
  if (transition === 'fade') {
    const fadeAmount = Math.sin(progress * Math.PI * 4) * 0.1 + 0.9;
    for (let i = 0; i < imageData.length; i += 4) {
      imageData[i] = Math.floor(imageData[i] * fadeAmount);
      imageData[i + 1] = Math.floor(imageData[i + 1] * fadeAmount);
      imageData[i + 2] = Math.floor(imageData[i + 2] * fadeAmount);
    }
  }
}

function drawCircle(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  centerX: number, 
  centerY: number, 
  radius: number, 
  color: { r: number; g: number; b: number; a: number }
) {
  for (let y = Math.max(0, centerY - radius); y <= Math.min(height - 1, centerY + radius); y++) {
    for (let x = Math.max(0, centerX - radius); x <= Math.min(width - 1, centerX + radius); x++) {
      const dx = x - centerX;
      const dy = y - centerY;
      const distance = Math.sqrt(dx * dx + dy * dy);
      
      if (distance <= radius) {
        const index = (y * width + x) * 4;
        const alpha = color.a / 255;
        const invAlpha = 1 - alpha;
        
        imageData[index] = Math.floor(imageData[index] * invAlpha + color.r * alpha);
        imageData[index + 1] = Math.floor(imageData[index + 1] * invAlpha + color.g * alpha);
        imageData[index + 2] = Math.floor(imageData[index + 2] * invAlpha + color.b * alpha);
      }
    }
  }
}

function drawText(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  text: string, 
  options: {
    x: number;
    y: number;
    size: 'small' | 'medium' | 'large';
    color: { r: number; g: number; b: number; a: number };
  }
) {
  // Simple text rendering using pixel manipulation
  const { x, y, size, color } = options;
  const charWidth = size === 'large' ? 12 : size === 'medium' ? 8 : 6;
  const charHeight = size === 'large' ? 16 : size === 'medium' ? 12 : 8;
  
  for (let i = 0; i < Math.min(text.length, 20); i++) {
    const charX = x + i * charWidth;
    if (charX + charWidth > width) break;
    
    // Draw simple character representation
    drawTextChar(imageData, width, height, charX, y, charWidth, charHeight, color);
  }
}

function drawTextChar(
  imageData: Uint8Array, 
  width: number, 
  height: number, 
  x: number, 
  y: number, 
  charWidth: number, 
  charHeight: number, 
  color: { r: number; g: number; b: number; a: number }
) {
  // Simple character drawing (rectangular representation)
  for (let dy = 0; dy < charHeight; dy++) {
    for (let dx = 0; dx < charWidth; dx++) {
      const pixelX = x + dx;
      const pixelY = y + dy;
      
      if (pixelX >= 0 && pixelX < width && pixelY >= 0 && pixelY < height) {
        // Create simple character pattern
        const shouldDraw = (dx === 0 || dx === charWidth - 1 || dy === 0 || dy === charHeight - 1 || 
                           (dx === Math.floor(charWidth / 2) && dy > 2 && dy < charHeight - 2));
        
        if (shouldDraw) {
          const index = (pixelY * width + pixelX) * 4;
          const alpha = color.a / 255;
          const invAlpha = 1 - alpha;
          
          imageData[index] = Math.floor(imageData[index] * invAlpha + color.r * alpha);
          imageData[index + 1] = Math.floor(imageData[index + 1] * invAlpha + color.g * alpha);
          imageData[index + 2] = Math.floor(imageData[index + 2] * invAlpha + color.b * alpha);
        }
      }
    }
  }
}

// Save frame data as PNG file
async function saveFrameAsPNG(frameData: FrameData, filePath: string): Promise<void> {
  // Create a simple PNG-like structure
  // In production, you'd use a proper PNG encoder
  const { width, height, data } = frameData;
  
  // Simple BMP format for demonstration (easier than PNG)
  const fileSize = 54 + (width * height * 4);
  const buffer = Buffer.alloc(fileSize);
  
  // BMP Header
  buffer.write('BM', 0); // Signature
  buffer.writeUInt32LE(fileSize, 2); // File size
  buffer.writeUInt32LE(54, 10); // Data offset
  buffer.writeUInt32LE(40, 14); // Header size
  buffer.writeUInt32LE(width, 18); // Width
  buffer.writeUInt32LE(height, 22); // Height
  buffer.writeUInt16LE(1, 26); // Planes
  buffer.writeUInt16LE(32, 28); // Bits per pixel
  
  // Pixel data (flip vertically for BMP)
  let bufferIndex = 54;
  for (let y = height - 1; y >= 0; y--) {
    for (let x = 0; x < width; x++) {
      const dataIndex = (y * width + x) * 4;
      buffer[bufferIndex++] = data[dataIndex + 2]; // B
      buffer[bufferIndex++] = data[dataIndex + 1]; // G
      buffer[bufferIndex++] = data[dataIndex];     // R
      buffer[bufferIndex++] = data[dataIndex + 3]; // A
    }
  }
  
  await fs.writeFile(filePath.replace('.png', '.bmp'), buffer);
}

// Encode video using FFmpeg
async function encodeVideoWithFFmpeg(options: {
  framePaths: string[];
  outputPath: string;
  width: number;
  height: number;
  frameRate: number;
  duration: number;
  voiceUrl?: string;
  musicUrl?: string;
  tempDir: string;
}): Promise<void> {
  const { framePaths, outputPath, width, height, frameRate, duration, voiceUrl, musicUrl, tempDir } = options;
  
  return new Promise(async (resolve, reject) => {
    try {
      console.log('üé¨ Starting FFmpeg encoding...');
      
      // Lazy-load FFmpeg
      const ffmpeg = await getFFmpeg();
      
      // Create FFmpeg command
      const command = ffmpeg()
        .input(path.join(tempDir, 'frame_%06d.bmp'))
        .inputFPS(frameRate)
        .videoCodec('libx264')
        .outputOptions([
          '-preset fast',
          '-crf 23',
          '-pix_fmt yuv420p',
          `-vf scale=${width}:${height}`,
          `-t ${duration}`
      ]);

    // Add audio if provided
    if (voiceUrl) {
      command.input(voiceUrl);
      if (musicUrl) {
        // Mix voice and music
        command.input(musicUrl);
        command.complexFilter([
          '[1:a]volume=1.0[voice]',
          '[2:a]volume=0.3[music]',
          '[voice][music]amix=inputs=2[audio]'
        ]);
        command.outputOptions(['-map 0:v', '-map [audio]']);
      } else {
        command.outputOptions(['-map 0:v', '-map 1:a']);
      }
      command.audioCodec('aac');
    } else if (musicUrl) {
      // Add only background music
      command.input(musicUrl);
      command.outputOptions(['-map 0:v', '-map 1:a']);
      command.audioCodec('aac');
    }

    command
      .output(outputPath)
      .on('start', (commandLine) => {
        console.log('üìΩÔ∏è FFmpeg command:', commandLine);
      })
      .on('progress', (progress) => {
        if (progress.percent) {
          process.stdout.write(`\rEncoding progress: ${Math.round(progress.percent)}%`);
        }
      })      .on('end', () => {
        console.log('\n‚úÖ FFmpeg encoding completed successfully');
        resolve();
      })
      .on('error', (error) => {
        console.error('\n‚ùå FFmpeg encoding failed:', error.message);
        reject(error);
      })
      .run();
    } catch (error) {
      console.error('‚ùå Failed to initialize FFmpeg:', error);
      reject(error);
    }
  });
}

// Cleanup temporary files
async function cleanupTempFiles(tempDir: string): Promise<void> {
  try {
    await fs.rm(tempDir, { recursive: true, force: true });
    console.log('üßπ Cleaned up temporary files');
  } catch (error) {
    console.warn('‚ö†Ô∏è Failed to cleanup temp files:', error);
  }
}

function getCurrentScene(scenes: Scene[], timeInVideo: number, totalDuration: number): Scene | null {
  const sceneIndex = Math.floor((timeInVideo / totalDuration) * scenes.length);
  return scenes[sceneIndex] || scenes[scenes.length - 1] || null;
}

function getVideoDimensions(videoType: string): { width: number; height: number } {
  switch (videoType) {
    case 'youtube-shorts':
    case 'instagram-reel':
    case 'tiktok-video':
      return { width: 1080, height: 1920 }; // Vertical
    case 'youtube-long':
    case 'explainer':
    default:
      return { width: 1920, height: 1080 }; // Horizontal
  }
}

function getAspectRatio(videoType: string): string {
  switch (videoType) {
    case 'youtube-shorts':
    case 'instagram-reel':
    case 'tiktok-video':
      return '9:16';
    case 'youtube-long':
    case 'explainer':
    default:
      return '16:9';
  }
}
